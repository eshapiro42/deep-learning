<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>Deep Learning</title><description>by Eric Shapiro</description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Deep Learning</title><link>http://localhost:2368/</link></image><generator>Ghost 2.23</generator><lastBuildDate>Thu, 30 May 2019 03:00:17 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Linear Regression with Neurons (2)</title><description>&lt;!--kg-card-begin: markdown--&gt;&lt;h1 id="morecomplicateddata"&gt;More complicated data&lt;/h1&gt;
&lt;p&gt;Last time, I introduced a simple artificial neuron with a single parameter, $w$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/05/one-parameter-neuron.svg" alt="one-parameter-neuron"&gt;&lt;/p&gt;
&lt;p&gt;We figured out how, given labeled training data&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; that was reasonably linear and passed through the origin, this neuron could learn to make reasonable predictions. The key to this was defining a cost&lt;/p&gt;</description><link>http://localhost:2368/linear-regression-with-neurons-2/</link><guid isPermaLink="false">5cef0fd6a38cb5010f177ea8</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Wed, 29 May 2019 23:09:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1499626662328-b83a935441a4?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded>&lt;!--kg-card-begin: markdown--&gt;&lt;h1 id="morecomplicateddata"&gt;More complicated data&lt;/h1&gt;
&lt;img src="https://images.unsplash.com/photo-1499626662328-b83a935441a4?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Linear Regression with Neurons (2)"&gt;&lt;p&gt;Last time, I introduced a simple artificial neuron with a single parameter, $w$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/05/one-parameter-neuron.svg" alt="Linear Regression with Neurons (2)"&gt;&lt;/p&gt;
&lt;p&gt;We figured out how, given labeled training data&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; that was reasonably linear and passed through the origin, this neuron could learn to make reasonable predictions. The key to this was defining a cost function to measure how poorly the neuron was performing for a given weight $w$, and then iteratively applying gradient descent to obtain new values of $w$, lower the cost and improve performance. That learning process can be summarized as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Choose an initial value for $w$.&lt;/li&gt;
&lt;li&gt;Feed our labeled data to the neuron.&lt;/li&gt;
&lt;li&gt;Compare each of the neuron's predictions to the true value from the training data.&lt;/li&gt;
&lt;li&gt;Compute the gradient of the cost function from these predictions.&lt;/li&gt;
&lt;li&gt;Apply one iteration of gradient descent to move $w$ in the direction that will lower the cost.&lt;/li&gt;
&lt;li&gt;Go back to step 2 and repeat until you're satisfied with the neuron's predictions.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now let's up it a notch. What if we still had linear training data, but it did not pass through the origin? Here's the data set we'll be working with for the remainder of this post:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/95.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;Spoiler alert: I generated this data using random fluctuations from the line $y=-2x+5$. These fluctuations are normally distributed with a mean of $0$ and a standard deviation of $2$. This data is therefore well suited for linear regression! ðŸ˜„&lt;/p&gt;
&lt;p&gt;Our training data consists of 1000 points. In table form, the data looks like this (in no particular order):&lt;/p&gt;
&lt;p&gt;$$\begin{array}{|c|c|c|}&lt;br&gt;
\hline&lt;br&gt;
i &amp;amp;   x           &amp;amp; y \\&lt;br&gt;
\hline&lt;br&gt;
1 &amp;amp;  -0.829779953 &amp;amp; 8.11066094 \\&lt;br&gt;
\hline&lt;br&gt;
2 &amp;amp;   2.20324493  &amp;amp; -0.0548983078 \\&lt;br&gt;
\hline&lt;br&gt;
3 &amp;amp;   -4.99885625 &amp;amp; 16.6263988 \\&lt;br&gt;
\hline&lt;br&gt;
4 &amp;amp;   -1.97667427 &amp;amp; 10.5142884 \\&lt;br&gt;
\hline&lt;br&gt;
5 &amp;amp;   -3.53244109 &amp;amp; 9.13677504 \\&lt;br&gt;
\hline&lt;br&gt;
\vdots &amp;amp; \vdots   &amp;amp; \vdots \\&lt;br&gt;
\hline&lt;br&gt;
\end{array}$$&lt;/p&gt;
&lt;p&gt;Since this data does not go through the origin, you might expect that if we train our one-parameter neuron with this data, we will not get very good predictions. Let's give it a try.&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-2-1?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;Here's the best fit line predicted by our one-parameter neuron after training on this data:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/99.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;That's... not great. It did manage to get the slope right, so our neuron is really doing everything it can to minimize its cost. It just doesn't have the ability to make a prediction that &lt;em&gt;doesn't&lt;/em&gt; go through the origin! So let's create a new neuron that does have this ability.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/05/two-parameter-neuron.svg" alt="Linear Regression with Neurons (2)"&gt;&lt;/p&gt;
&lt;p&gt;We haven't done anything groundbreaking here. All we've done is add a new parameter $b$ to the neuron which is also used in computing the neuron's output. We call $b$ the neuron's &lt;strong&gt;bias&lt;/strong&gt;. Given an input value $x_i$, the neuron will now output the prediction $\hat{y_i} = wx_i+b$, using both the weight and the bias.&lt;/p&gt;
&lt;p&gt;Our loss function stays the same for each data point,&lt;/p&gt;
&lt;p&gt;$$L(x_i) = (y_i - \hat{y_i})^2,$$&lt;/p&gt;
&lt;p&gt;as does our cost function for the entire neuron,&lt;/p&gt;
&lt;p&gt;$$C = \frac{1}{m}\sum_{i=1}^m L(x_i).$$&lt;/p&gt;
&lt;p&gt;(Recall that $m$ is the number of points in our training data.)&lt;/p&gt;
&lt;p&gt;However, our predictions $\hat{y}$ are now calculated using a new formula. Since we've doubled the number of parameters in our neuron, we need to rethink how we do gradient descent.&lt;/p&gt;
&lt;h1 id="gradientdescentwithtwoparameters"&gt;Gradient descent with two parameters&lt;/h1&gt;
&lt;p&gt;With two parameters, our cost function becomes a little more complicated. It's now a function of two variables, $w$ and $b$. If we were to visualize the cost function for our data over a range of different values of weights and biases, it would look like this:&lt;/p&gt;
&lt;iframe width="100%" height="500" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/103.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;If you move the surface around a bit, you'll notice that the optimal weight is roughly $-2$ and the optimal bias is roughly $5$, just as we'd expect.&lt;/p&gt;
&lt;p&gt;Luckily, differential calculus doesn't get too much more complicated as we add dimensions. The gradient is no longer just the derivative of our cost function. It is really a vector of its partial derivatives. That is,&lt;/p&gt;
&lt;p&gt;$$\nabla C = \begin{bmatrix}&lt;br&gt;
\dfrac{\partial C}{\partial w} \\[.5em]&lt;br&gt;
\dfrac{\partial C}{\partial b}&lt;br&gt;
\end{bmatrix}.$$&lt;/p&gt;
&lt;p&gt;If this is gibberish to you, don't worry. You don't need to follow along with the math to get a sense of what's going on.&lt;/p&gt;
&lt;p&gt;We calculate the partial derivatives much the same way we calculated the ordinary derivative last time â€” using the chain rule.&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\p{C}{w} &amp;amp;= \sum_{i=1}^m \p{C}{L_i} \p{L_i}{\hat{y}_i} \p{\hat{y}_i}{w}, \\&lt;br&gt;
\p{C}{b} &amp;amp;= \sum_{i=1}^m \p{C}{L_i} \p{L_i}{\hat{y}_i} \p{\hat{y}_i}{b}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;The intermediate partial derivatives are as follows:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\p{C}{L_i} &amp;amp;= \tfrac{1}{m}, \\&lt;br&gt;
\p{L_i}{\hat{y}_i} &amp;amp;= -2(y_i-\hat{y}_i), \\&lt;br&gt;
\p{\hat{y}_i}{w} &amp;amp;= x_i, \\&lt;br&gt;
\p{\hat{y}_i}{b} &amp;amp;= 1.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Combining these using the chain rule, we see that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\p{C}{w} &amp;amp;= -\frac{2}{m} \sum_{i=1}^m (y_i - \hat{y}_i) x_i, \\&lt;br&gt;
\p{C}{b} &amp;amp;= -\frac{2}{m} \sum_{i=1}^m (y_i - \hat{y}_i).&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;The partial derivative with respect to $w$ is actually the same as last time, and the derivative with respect to $b$ is actually simpler. Each component of the gradient tells us the direction of steepest ascent of the cost function $C$ in that direction. So, for instance, $\p{C}{w}$ gives the direction of steepest ascent in the $w$ direction at any point.&lt;/p&gt;
&lt;p&gt;Our gradient descent algorithm doesn't have to change too much! We just update each variable independently according to its component of the gradient. That is, if $\alpha$ represents our chosen learning rate, we update our parameters according to the rules:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
w &amp;amp;\to w - \alpha\p{C}{w} \\&lt;br&gt;
b &amp;amp;\to b - \alpha\p{C}{b}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;If we iterate our gradient descent algorithm enough times with a good choice of learning rate and a little luck, we should always arrive at a choice of parameters $w$ and $b$ which minimizes the cost of our neuron!&lt;/p&gt;
&lt;p&gt;As an aside, we can actually find the optimum cost analytically, just as we did last time. The mimimum value occurs where the gradient is zero, i.e., where each partial derivative is zero. This gives us two equations in two unknowns, which can be solved with some algebra. I will not go through the specifics, but the cost is minimized when&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
w &amp;amp;= \dfrac{m \sum_{i=1}^m x_i y_i - \sum_{i=1}^m x_i \sum_{i=1}^m y_i}{m \sum_{i=1}^m x_i^2 - \big(\sum_{i=1}^m x_i\big)^2}, \\[1em]&lt;br&gt;
b &amp;amp;= \dfrac{\sum_{i=1}^m y_i \sum_{i=1}^m x^2 - \sum_{i=1}^m x_i \sum_{i=1}^m x_i y_i}{m \sum_{i=1}^m x_i^2 - \big(\sum_{i=1}^m x_i\big)^2}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;This technique of finding the optimal values of $w$ and $b$ analytically is called &lt;strong&gt;linear regression&lt;/strong&gt;, and in the case of our training data it results in the following values:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
w &amp;amp;= -1.99787325, \\&lt;br&gt;
b &amp;amp;= 5.09462935.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;h1 id="testingourneuron"&gt;Testing our neuron&lt;/h1&gt;
&lt;p&gt;Let's see how close our two-parameter neuron comes to finding these optimal values!&lt;/p&gt;
&lt;p&gt;The following is Python code which implements the algorithm for gradient descent that we've just described, updating the parameters $w$ and $b$ simultaneously according to their respective components of the gradient. Note that the &lt;code&gt;TwoParameterNeuron&lt;/code&gt; class inherits from the same &lt;code&gt;Neuron&lt;/code&gt; class that I defined in my last post.&lt;/p&gt;
&lt;script src="https://gist.github.com/eshapiro42/89cfaf59b6ad7ee6e0a346aca82ce9fa.js"&gt;&lt;/script&gt;
&lt;br&gt;
&lt;p&gt;If we train this neuron for 100 epochs on the training data defined at the beginning of this post, with a learning rate of 0.01, here's what happens:&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-2-2?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;Uh oh! Our neuron reached a pretty good value for $w$, but that value for $b$ is still pretty far off. What happened?&lt;/p&gt;
&lt;p&gt;Notice how the cost is still decreasing substantially with every iteration. Here's a plot of the neuron's cost as a function of the number of epochs it's trained for:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/105.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;Okay, so maybe &amp;quot;substantially&amp;quot; was an overstatement, but the cost is definitely still going down! This implies that we haven't trained our neuron long enough. Let's try training it longer â€” we'll try 1000 epochs â€” and see if it does any better.&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-2-3?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;Much better! Now our neuron's definitely on par with linear regression!&lt;/p&gt;
&lt;p&gt;Here's another plot of the cost over these 1000 epochs of gradient descent:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/109.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;The cost is definitely not decreasing by much anymore by the time 1000 epochs have passed. Notice how toward the beginning of training, the cost was decreasing a lot faster than toward the end. This is fairly common. In the early iterations of gradient descent, our parameters are typically very far from their targets and need to be adjusted by large amounts to compensate. Then as they begin to get better and better, gradient descent continues to fine-tune them but does not have quite as much to do anymore.&lt;/p&gt;
&lt;p&gt;To wrap things up, let's take a look at how our two-parameter neuron is fitting our data after being trained for 1000 epochs:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/111.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;I'd say that looks pretty good.&lt;/p&gt;
&lt;h1 id="whatsnext"&gt;What's next?&lt;/h1&gt;
&lt;p&gt;That's about it for linear regression. In my next post, I'll talk about adding non-linear activations to our neurons and combining them to form larger networks!&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;By labeled training data, I mean data consisting of values for both the inputs and the corresponding observed outputs. This is the data that we want our neuron to learn from so it can generate reasonable predictions. &lt;a href="#fnref1" class="footnote-backref"&gt;â†©ï¸Ž&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
&lt;!--kg-card-end: markdown--&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title>Linear Regression With Neurons (1)</title><description>&lt;!--kg-card-begin: markdown--&gt;&lt;h1 id="whatareneurons"&gt;What are neurons?&lt;/h1&gt;
&lt;br&gt;
&lt;p&gt;The goal of this post is to introduce &lt;strong&gt;artificial neurons&lt;/strong&gt; â€” the basic building blocks of a neural network â€” as well as the way in which they learn. Their general concept is based on their namesake, the neurons of the human brain.&lt;/p&gt;
&lt;!--kg-card-end: markdown--&gt;&lt;!--kg-card-begin: image--&gt;&lt;figure class="kg-card kg-image-card kg-card-hascaption"&gt;&lt;img src="http://localhost:2368/content/images/2019/05/biological-neuron-1.jpg" class="kg-image"&gt;&lt;figcaption&gt;Biological Neurons&lt;/figcaption&gt;&lt;/figure&gt;&lt;!--kg-card-end: image--&gt;&lt;!--kg-card-begin: markdown--&gt;&lt;p&gt;I'm no expert in&lt;/p&gt;</description><link>http://localhost:2368/linear-regression-with-neurons/</link><guid isPermaLink="false">5cedff53a38cb5010f177e6e</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Tue, 28 May 2019 02:42:02 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1511268594014-0e9d3ea5c33e?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded>&lt;!--kg-card-begin: markdown--&gt;&lt;h1 id="whatareneurons"&gt;What are neurons?&lt;/h1&gt;
&lt;br&gt;
&lt;img src="https://images.unsplash.com/photo-1511268594014-0e9d3ea5c33e?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Linear Regression With Neurons (1)"&gt;&lt;p&gt;The goal of this post is to introduce &lt;strong&gt;artificial neurons&lt;/strong&gt; â€” the basic building blocks of a neural network â€” as well as the way in which they learn. Their general concept is based on their namesake, the neurons of the human brain.&lt;/p&gt;
&lt;!--kg-card-end: markdown--&gt;&lt;!--kg-card-begin: image--&gt;&lt;figure class="kg-card kg-image-card kg-card-hascaption"&gt;&lt;img src="http://localhost:2368/content/images/2019/05/biological-neuron-1.jpg" class="kg-image" alt="Linear Regression With Neurons (1)"&gt;&lt;figcaption&gt;Biological Neurons&lt;/figcaption&gt;&lt;/figure&gt;&lt;!--kg-card-end: image--&gt;&lt;!--kg-card-begin: markdown--&gt;&lt;p&gt;I'm no expert in cognitive science, but from what I understand a biological neuron receives a number of electrical impulses from surrounding neurons. Then, based on the cumulative intensity of these signals, the neuron might send out an electrical impulse of its own. This impulse is then transmitted to other neurons, which each decide whether to fire, ad infinitum.&lt;/p&gt;
&lt;p&gt;The mechanism which determines whether a particular neuron will fire given a set of input signals is still mysterious, but luckily we are not too concerned with it. We care only about the general behavior: a neuron takes a set of inputs, processes them in some way, and returns an output. This is exactly what our artificial neurons will do, just in a more transparent way.&lt;/p&gt;
&lt;p&gt;In the next post, I will give the full definition of an artificial neuron. For now, let's look at a minimal example â€” a neuron with a single input and a single parameter:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/05/one-parameter-neuron.svg" alt="Linear Regression With Neurons (1)"&gt;&lt;/p&gt;
&lt;p&gt;This neuron takes a single number $x$ as an input, multiplies it by a &lt;strong&gt;weight&lt;/strong&gt; $w$, and returns their product, $wx$.&lt;/p&gt;
&lt;p&gt;It is important to note that the neuron's weight $w$ is part of the neuron itself, and thus it remains fixed no matter what input $x$ is fed to the neuron. However, the input can be any number. So, for instance, if $w=5$, then the neuron outputs $5x$ for any input $x$.&lt;/p&gt;
&lt;p&gt;So technically this neuron is just the function $N:\R\to\R$ defined by $N(x) = wx$, where $w\in\R$ is fixed. It is often useful to keep this function representation in the back of our minds, but we will prefer the graphical interpretation where a neuron is represented by a node, connected to inputs and outputs.&lt;/p&gt;
&lt;h1 id="howdoneuronslearn"&gt;How do neurons learn?&lt;/h1&gt;
&lt;p&gt;Now that you know how our one-parameter, single input neuron acts on inputs, it's time to see how we can train our neuron to make meaningful predictions. I will demonstrate this with the simplest example I can think of.&lt;/p&gt;
&lt;p&gt;Let's say we're given the following data, collected from three people at the grocery store, where $x$ represents the number of items they purchased and $y$ represents how much they paid, in dollars:&lt;/p&gt;
&lt;p&gt;$$\begin{array}{|c|c|c|}&lt;br&gt;
\hline&lt;br&gt;
\text{Person} &amp;amp; x = \text{Items} &amp;amp; y = \text{Price} \\&lt;br&gt;
\hline&lt;br&gt;
\text{Sally}  &amp;amp; 1                &amp;amp; 2                \\&lt;br&gt;
\hline&lt;br&gt;
\text{Adam}   &amp;amp; 2                &amp;amp; 4                \\&lt;br&gt;
\hline&lt;br&gt;
\text{Fred}   &amp;amp; 3                &amp;amp; 6                \\&lt;br&gt;
\hline&lt;br&gt;
\end{array}$$&lt;/p&gt;
&lt;p&gt;Seeing this table, it might be immediately apparent to you that $y=2x$ for each $x$ in the table. In practice, however, we are often faced with much larger amounts of data that do not follow such a clear trend. We would thus like our neuron to learn for itself how best to make predictions, based on the data. So in this case, we would like the neuron to figure out that it should set $w=2$.&lt;/p&gt;
&lt;p&gt;As simple as the problem is, this is easier said than done. But let's walk through training the neuron on our data set, step by step. To start off, we need to pick some value for $w$, so the neuron can actually do anything at all. Let's choose $w=0$, and see what predictions our neuron makes:&lt;/p&gt;
&lt;p&gt;$$\begin{array}{|c|c|c|}&lt;br&gt;
\hline&lt;br&gt;
x &amp;amp; \hat{y} = wx &amp;amp; y \\&lt;br&gt;
\hline&lt;br&gt;
1 &amp;amp; 0            &amp;amp; 2 \\&lt;br&gt;
\hline&lt;br&gt;
2 &amp;amp; 0            &amp;amp; 4 \\&lt;br&gt;
\hline&lt;br&gt;
3 &amp;amp; 0            &amp;amp; 6 \\&lt;br&gt;
\hline&lt;br&gt;
\end{array}$$&lt;/p&gt;
&lt;p&gt;Here, $\hat{y}$ represents the prediction made given the input value $x$, and $y$ represents the true value from our data set. It's safe to say that choosing $w=0$ is not giving us very good predictions. We would like to adjust $w$ so that the neuron does a better job. In order to do this, we need some way to measure just how badly the neuron is currently performing.&lt;/p&gt;
&lt;p&gt;We define the &lt;strong&gt;loss&lt;/strong&gt; of the neuron for a single input value $x_i$ as follows:&lt;/p&gt;
&lt;p&gt;$$L(x_i) = (y_i - \hat{y_i})^2.$$&lt;/p&gt;
&lt;p&gt;This loss function $L$ basically tells us how badly the neuron is doing at predicting a single value $x_i$. Notice that if the prediction $\hat{y_i}$ is close to the actual value $y_i$, the loss will be small (positive, but close to zero). If the neuron is perfectly predicting the output, the loss will be exactly zero. If the neuron is given an input $x_i$ and spits out a terrible answer $\hat{y}_i$ that is very far from the true answer $y$, then the loss for that input will be huge.&lt;/p&gt;
&lt;p&gt;In the case of our example,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
L(x_1) &amp;amp;= (y_1 - \hat{y}_1)^2 = (2 - 0)^2 = 4, \\&lt;br&gt;
L(x_2) &amp;amp;= (y_2 - \hat{y}_2)^2 = (4 - 0)^2 = 16, \\&lt;br&gt;
L(x_3) &amp;amp;= (y_3 - \hat{y}_3)^2 = (6 - 0)^2 = 36.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Notice that the loss for $x_1$ is small because the prediction is not too far from the actual result. As the predictions get further off, the losses grow exponentially.&lt;/p&gt;
&lt;p&gt;The loss function we've just defined is called the &lt;strong&gt;squared error&lt;/strong&gt;, for obvious reasons. We could have defined a different loss function, if we'd wanted. For instance, we could have taken $L(x_i)=\abs{y_i - \hat{y}_i}$. This is called &lt;strong&gt;absolute error&lt;/strong&gt;, but it is not used very often for reasons we will see shortly. There are plenty of other choices as well, but squared error will do just fine for now.&lt;/p&gt;
&lt;p&gt;Now that we have a measure for how poorly the neuron is performing for a single input, how can we measure how poorly the neuron is doing overall? The answer is simple â€” we can just average all the losses.&lt;/p&gt;
&lt;p&gt;We define the &lt;strong&gt;cost&lt;/strong&gt; of the neuron to be&lt;/p&gt;
&lt;p&gt;$$C = \frac{1}{m}\sum_{i=1}^m L(x_i),$$&lt;/p&gt;
&lt;p&gt;where $m$ is the total number of data points (so in our case, $m=3$). This is literally just the average loss, computed over all the data. In our case,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
C &amp;amp;= \tfrac{1}{3}\big(L(x_1)+L(x_2)+L(x_2)\big) \\&lt;br&gt;
&amp;amp;= \tfrac{1}{3}(4 + 16 + 36) \\&lt;br&gt;
&amp;amp;= \tfrac{56}{3} \\&lt;br&gt;
&amp;amp;\approx 18.6666666667.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Because we have chosen our loss function to be the squared error, and our cost is the mean of the losses, this cost function is called &lt;strong&gt;mean squared error&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So the goal now becomes &lt;em&gt;minimizing the cost&lt;/em&gt; of our neuron! Once we have settled on a weight which makes the cost sufficiently low, we say our neuron is &lt;strong&gt;trained&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Okay, so our neuron currently has a cost of $18.6666666667$. This doesn't really tell us too much by itself. We want the network to choose a new weight which will result in a lower cost. How can we accomplish this?&lt;/p&gt;
&lt;p&gt;One idea would be to keep randomly selecting weights and keeping track of which results in the lowest cost, i.e., is giving the best predictions according to our metric.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 1. Random Guessing&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Decide on some reasonable interval $[a, b]$ to search.&lt;/li&gt;
&lt;li&gt;Initialize &lt;code&gt;best_w = 0&lt;/code&gt; and &lt;code&gt;best_cost = infinity&lt;/code&gt; (or some very large number).&lt;/li&gt;
&lt;li&gt;Pick &lt;code&gt;w&lt;/code&gt; randomly in the interval $[a, b]$.&lt;/li&gt;
&lt;li&gt;Compute the cost &lt;code&gt;C&lt;/code&gt; of the neuron with the weight &lt;code&gt;w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;C&lt;/code&gt; is smaller than &lt;code&gt;best_cost&lt;/code&gt;, set &lt;code&gt;best_cost = C&lt;/code&gt; and &lt;code&gt;best_w = w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go back to step 3 and repeat for as long as you like.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;But this is not really a good solution, since there are infinite numbers to choose from and the neuron has no idea where to look. (And in fact, in the general case of a network with many neurons it will probably never find decent weights.)&lt;/p&gt;
&lt;p&gt;What the neuron really needs is some context. Maybe it could try out two new weights, one slightly less than $0$ and one slightly greater than $0$, and see which weight results in a lower cost. So for instance, maybe we could try $-0.1$ and $0.1$. I won't bore you with the details of the computation, but what we end up with is:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
C_{-0.1} &amp;amp;= 20.58, \\[.5em]&lt;br&gt;
C_{0.1}  &amp;amp;= 16.8466666667.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;What this tells us is that we can get better performance out of our neuron if we increase the weight $w$ from $0$ to $0.1$, whereas if we had decreased the weight then the neuron would have given us worse predictions. This seems correct, since we know in the back of our minds that the value of $w$ that would give perfect predictions is actually $2$, so we certainly want it to increase from $0$. We could keep repeating this process until shifting the weight in either direction would give a worse (higher) cost, and then we would be done.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 2. Weight Sliding&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialize &lt;code&gt;w = 0&lt;/code&gt; and pick a small increment &lt;code&gt;increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compute the costs &lt;code&gt;C_minus&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;C_plus&lt;/code&gt; for the weights &lt;code&gt;w&lt;/code&gt;, &lt;code&gt;w - increment&lt;/code&gt; and &lt;code&gt;w + increment&lt;/code&gt;, respectively.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;C_minus&lt;/code&gt; is less than &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;C_plus&lt;/code&gt;, update &lt;code&gt;C = C_minus&lt;/code&gt; and &lt;code&gt;w = w - increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If instead &lt;code&gt;C_plus&lt;/code&gt; is less than &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;C_minus&lt;/code&gt;, update &lt;code&gt;C = C_plus&lt;/code&gt; and &lt;code&gt;w = w + increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Otherwise, &lt;code&gt;C&lt;/code&gt; is less than &lt;code&gt;C_minus&lt;/code&gt; and &lt;code&gt;C_plus&lt;/code&gt;, so we are done.&lt;/li&gt;
&lt;li&gt;Go back to step 2, but don't bother recomputing &lt;code&gt;C&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;This isn't such a bad method. It will usually tell us which direction we should nudge the weight to improve the neuron's predictions. However, it always takes fixed-size steps, it is not foolproof and it does poorly from a computational standpoint â€” it requires us to compute the cost three times for each choice of weight, and compare them. It turns out there's a much better way!&lt;/p&gt;
&lt;h1 id="gradientdescent"&gt;Gradient descent&lt;/h1&gt;
&lt;p&gt;It turns out that we can figure out which direction to shift the weight, and by how far, with a single computation. The actual method requires some knowledge of calculus, but the basic ideas should make sense to anyone following along. Just don't get scared off by the derivatives if you don't know what they are.&lt;/p&gt;
&lt;p&gt;Here is a plot of the cost for our neuron for a whole interval of possible weights. I computed this by calculating the cost associated with a bunch of weights in the interval $[-1, 5]$.&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/18.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;Computing this whole graph is similar to Algorithm 2 above. That is, it's very inefficient and computationally intensive. The graph is solely for the sake of our visualizing the problem. Our neuron does not know the shape of the cost function, so it needs some other way update its weight for a better prediction.&lt;/p&gt;
&lt;p&gt;The inspiration behind the gradient descent algorithm comes from the idea of a ball rolling down a hill. The idea is that gravity will always pull the ball in the direction of &lt;em&gt;steepest descent&lt;/em&gt;. For a visualization, press &amp;quot;Play&amp;quot; on the animation below.&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/82.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;Of course, in real life the momentum of the ball would keep it moving to the right for a little while after it reached the bottom, then it would change directions and oscillate for a short time before finally settling at the bottom. But we don't care too much about the details, only the general idea.&lt;/p&gt;
&lt;p&gt;It just so happens that we have a way to compute, at any given point, the direction of steepest descent. Recall that the derivative of a function at a point (if it exists) tells us geometrically the slope of the tangent line to the function's curve at that point. Here's what the tangent line to the cost curve looks like when $w=0$:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/83.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;The slope of this tangent line is negative, implying that the cost is decreasing as we move to the right. This means that if the derivative is negative, we want to shift our weight to the right. And if the derivative is positive, we want the weight to shift to the left.&lt;/p&gt;
&lt;p&gt;Since the derivative at $w=0$ is negative, we shift $w$ to the right a bit, then reevaluate:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/85.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;The derivative is still negative, but it's &lt;em&gt;less&lt;/em&gt; negative. So we should continue to shift $w$ to the right, but maybe not as much this time.&lt;/p&gt;
&lt;p&gt;If we continue this process, we should eventually shift $w$ to $2$, where the derivative is $0$. That is, the cost has a horizontal tangent line at this point. This is what tells us we have found a weight that minimzes the cost!&lt;/p&gt;
&lt;p&gt;The amount that we shift $w$ by in each iteration should be &lt;em&gt;proportional&lt;/em&gt; to the magnitude of the derivative. That way it will move by a lot more when the cost is very high and a lot less when the cost is very low, so we don't overshoot our target by too much. Said another way, this will guarantee that if our weight is close to optimal, we shift it by a smaller amount than if it is far from optimal. We call this proportionality constant the learning rate, and I will talk more about learning rates in another post.&lt;/p&gt;
&lt;p&gt;So here's the algorithm:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 3. Gradient Descent&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pick an initial weight &lt;code&gt;w&lt;/code&gt; using some predetermined method, and a small learning rate &lt;code&gt;learning_rate&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compute the derivative of the cost with respect to &lt;code&gt;w&lt;/code&gt;, call it &lt;code&gt;D_w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Update &lt;code&gt;w = w - learning_rate * D_w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go back to step 2 and repeat for as long as you like, or until &lt;code&gt;D_w&lt;/code&gt; is zero.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;This algorithm, as simple as it may seem, forms the basis for how neural networks learn from data.&lt;/p&gt;
&lt;h1 id="computingthegradient"&gt;Computing the gradient&lt;/h1&gt;
&lt;p&gt;Since our neuron only has one weight to optimize, in this case 'gradient' just means derivative. We will shortly see an example where this is no longer the case. But for now, we need to figure out a way of calculating the derivative of our cost function for a specific value of $w$. That is, we need to find $\d{C}{w}$.&lt;/p&gt;
&lt;p&gt;Recall that $C$ is a function of the losses $L_i$, which are in turn functions of the outputs $\hat{y_i}$, which are in turn functions of the inputs $x_i$. Here are the equations governing these relationships:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
C &amp;amp;= \frac{1}{m}\sum_{i=1}^m L_i, \\&lt;br&gt;
L_i &amp;amp;= (y_i - \hat{y_i})^2, \\[1em]&lt;br&gt;
\hat{y}_i &amp;amp;= wx_i.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;The chain rule tells us precisely how to calculate $\d{C}{w}$ from these equations! Through repeated use of the chain rule, we see that:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\d{C}{w} &amp;amp;= \sum_{i=1}^m\p{C}{L_i}\d{L_i}{w} \\&lt;br&gt;
&amp;amp;= \sum_{i=1}^m\p{C}{L_i}\d{L_i}{\hat{y_i}}\d{\hat{y_i}}{w}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;These three quantities are easy to calculate from the equations above:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\p{C}{L_i} &amp;amp;= \tfrac{1}{m}, \\&lt;br&gt;
\d{L_i}{\hat{y_i}} &amp;amp;= -2(y_i-\hat{y_i}), \\&lt;br&gt;
\d{\hat{y_i}}{w} &amp;amp;= x_i.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Combining these using the chain rule, we see that&lt;/p&gt;
&lt;p&gt;$$\d{C}{w} = -\frac{2}{m} \sum_{i=1}^m (y_i-\hat{y_i})x_i.$$&lt;/p&gt;
&lt;p&gt;This means we can use the following algorithm to compute the gradient of our cost function for a particular value of $w$:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 4. Gradient Computation&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialize &lt;code&gt;D_w = 0&lt;/code&gt;, set &lt;code&gt;x&lt;/code&gt; to the first input and &lt;code&gt;y&lt;/code&gt; to its corresponding output in our data set, and set &lt;code&gt;m&lt;/code&gt; to the number of data points.&lt;/li&gt;
&lt;li&gt;Compute the neuron's output &lt;code&gt;y_hat = w * x&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compute the contribution to &lt;code&gt;D_w&lt;/code&gt; from this data point, &lt;code&gt;D_w = D_w - 2 * (y - y_hat) * x&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;x&lt;/code&gt; to the next input and &lt;code&gt;y&lt;/code&gt; to its corresponding output, go back to step 2 and repeat until we have exhausted all our data.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;D_w = D_w / m&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;For this one-parameter network, it is easy to explicitly compute the optimal weight, since we have a formula for $\d{C}{w}$. From calculus, we know that the cost's minimum must occur when $\d{C}{w}=0$. That is, when&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
0 &amp;amp;= -\frac{2}{m} \sum_{i=1}^m (y_i-\hat{y_i})x_i \\&lt;br&gt;
&amp;amp;= -\frac{2}{m} \sum_{i=1}^m (y_i-wx_i)x_i \\&lt;br&gt;
&amp;amp;= -\frac{2}{m} \sum_{i=1}^m y_ix_i + \frac{2w}{m} \sum_{i=1}^m x_i^2.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;This is easily solved for $w$:&lt;/p&gt;
&lt;p&gt;$$w = \frac{\sum_{i=1}^m y_ix_i}{\sum_{i=1}^m x_i^2}.$$&lt;/p&gt;
&lt;p&gt;This technique for finding $w$ is conventionally called &lt;strong&gt;least squares linear regression through the origin&lt;/strong&gt;. In the case of our example, this becomes, as expected,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
w &amp;amp;= \tfrac{2\cdot 1 + 4\cdot 2 + 6\cdot 3}{1^2 + 2^2 + 3^2} \\&lt;br&gt;
&amp;amp;= \tfrac{28}{14} \\[.5em]&lt;br&gt;
&amp;amp;= 2.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;So our one-parameter neuron is really no match for what we can do analytically. But that's not the point. When we work with more complicated neurons, and link them together into neural networks, they quickly begin to solve problems that we do not have other mathematical tools to solve. And optimizing their parameters becomes impossible to do analytically, but gradient descent has no problem with it!&lt;/p&gt;
&lt;h1 id="puttingittogether"&gt;Putting it together&lt;/h1&gt;
&lt;p&gt;We have now completely described our one-parameter neuron and how it learns! Below is some Python code which encapsulates our model and allows us to train a neuron given input and output data. The first class, &lt;code&gt;Neuron&lt;/code&gt;, is a base class which we will continue to use as we implement more complex neurons. The second, &lt;code&gt;OneParameterNeuron&lt;/code&gt;, inherits from &lt;code&gt;Neuron&lt;/code&gt; and is a complete model of our one-parameter neuron.&lt;/p&gt;
&lt;script src="https://gist.github.com/eshapiro42/639a1d69d8239a23318ca2bb6cf8b934.js"&gt;&lt;/script&gt;
&lt;br&gt;
&lt;p&gt;Calling the &lt;code&gt;train&lt;/code&gt; method for a neuron launches 100 iterations, or &lt;strong&gt;epochs&lt;/strong&gt;, of gradient descent. It defaults to zero as an initial choice of weight, and uses a learning rate of $0.01$.&lt;/p&gt;
&lt;p&gt;Let's see it in action!&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-1?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;It actually works! Look how small our model got the cost after just 100 epochs of gradient descent! And look how close it got to the optimal value of $w=2$.&lt;/p&gt;
&lt;p&gt;There are some huge improvements that could be made to this code, in particular the &lt;code&gt;cost&lt;/code&gt; and &lt;code&gt;compute_gradient&lt;/code&gt; methods could be drastically sped up. However, this accurately reflects the algorithms we've discussed so far.&lt;/p&gt;
&lt;p&gt;It could be interesting to try training our neuron on a larger, not-so-perfect data set. We'll use this data, which consists of 1000 points which follow the same general trend as our previous data, but no longer sit perfectly on the line $y=2x$. This is more like data we might encounter in the real world!&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/89.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;p&gt;Watch what happens when we train our neuron with this new data:&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-2?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;It still did a pretty good job! Of course, it can't get the cost down as low anymore, but that's because the data is no longer perfectly linear and so there is some unavoidable error in any linear model of the data. Here is the trendline that our model predicted, superimposed on the data:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="https://plot.ly/~eshapiro/93.embed?showlink=false"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;I'd say that looks pretty good! As a comparison, least squares linear regression through the origin predicts a slope of $1.95078950636752$ for this same data.&lt;/p&gt;
&lt;p&gt;This post is getting pretty long, so I'll leave it at that for now. In my next post, we'll improve our neuron by adding a second parameter, and we'll see how this makes everything a bit more complicated.&lt;/p&gt;
&lt;!--kg-card-end: markdown--&gt;</content:encoded></item></channel></rss>