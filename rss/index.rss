<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>Deep Learning</title><description>by Eric Shapiro</description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Deep Learning</title><link>http://localhost:2368/</link></image><generator>Ghost 2.23</generator><lastBuildDate>Wed, 29 May 2019 03:12:24 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Linear Regression With Neurons (1)</title><description>&lt;!--kg-card-begin: markdown--&gt;&lt;h1 id="whatareneurons"&gt;What are neurons?&lt;/h1&gt;
&lt;br&gt;
&lt;p&gt;The goal of this post is to introduce &lt;strong&gt;artificial neurons&lt;/strong&gt; — the basic building blocks of a neural network — as well as the way in which they learn. Their general concept is based on their namesake, the neurons of the human brain.&lt;/p&gt;
&lt;!--kg-card-end: markdown--&gt;&lt;!--kg-card-begin: image--&gt;&lt;figure class="kg-card kg-image-card kg-card-hascaption"&gt;&lt;img src="http://localhost:2368/content/images/2019/05/biological-neuron-1.jpg" class="kg-image"&gt;&lt;figcaption&gt;Biological Neurons&lt;/figcaption&gt;&lt;/figure&gt;&lt;!--kg-card-end: image--&gt;&lt;!--kg-card-begin: markdown--&gt;&lt;p&gt;I'm no expert in&lt;/p&gt;</description><link>http://localhost:2368/linear-regression-with-neurons/</link><guid isPermaLink="false">5cec9d87a38cb5010f177d45</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Tue, 28 May 2019 02:42:02 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1511268594014-0e9d3ea5c33e?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded>&lt;!--kg-card-begin: markdown--&gt;&lt;h1 id="whatareneurons"&gt;What are neurons?&lt;/h1&gt;
&lt;br&gt;
&lt;img src="https://images.unsplash.com/photo-1511268594014-0e9d3ea5c33e?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Linear Regression With Neurons (1)"&gt;&lt;p&gt;The goal of this post is to introduce &lt;strong&gt;artificial neurons&lt;/strong&gt; — the basic building blocks of a neural network — as well as the way in which they learn. Their general concept is based on their namesake, the neurons of the human brain.&lt;/p&gt;
&lt;!--kg-card-end: markdown--&gt;&lt;!--kg-card-begin: image--&gt;&lt;figure class="kg-card kg-image-card kg-card-hascaption"&gt;&lt;img src="http://localhost:2368/content/images/2019/05/biological-neuron-1.jpg" class="kg-image" alt="Linear Regression With Neurons (1)"&gt;&lt;figcaption&gt;Biological Neurons&lt;/figcaption&gt;&lt;/figure&gt;&lt;!--kg-card-end: image--&gt;&lt;!--kg-card-begin: markdown--&gt;&lt;p&gt;I'm no expert in cognitive science, but from what I understand a biological neuron receives a number of electrical impulses from surrounding neurons. Then, based on the cumulative intensity of these signals, the neuron might send out an electrical impulse of its own. This impulse is then transmitted to other neurons, which each decide whether to fire, ad infinitum.&lt;/p&gt;
&lt;p&gt;The mechanism which determines whether a particular neuron will fire given a set of input signals is still mysterious, but luckily we are not too concerned with it. We care only about the general behavior: a neuron takes a set of inputs, processes them in some way, and returns an output. This is exactly what our artificial neurons will do, just in a more transparent way.&lt;/p&gt;
&lt;p&gt;In the next post, I will give the full definition of an artificial neuron. For now, let's look at a minimal example — a neuron with a single input and a single parameter: &lt;img src="http://localhost:2368/content/images/2019/05/one-parameter-neuron.svg" alt="Linear Regression With Neurons (1)"&gt; This neuron takes a single number $x$ as an input, multiplies it by a &lt;strong&gt;weight&lt;/strong&gt; $w$, and returns their product, $wx$.&lt;/p&gt;
&lt;p&gt;It is important to note that the neuron's weight $w$ is part of the neuron itself, and thus it remains fixed no matter what input $x$ is fed to the neuron. However, the input can be any number. So, for instance, if $w=5$, then the neuron outputs $5x$ for any input $x$.&lt;/p&gt;
&lt;p&gt;So technically this neuron is just the function $N:\R\to\R$ defined by $N(x) = wx$, where $w\in\R$ is fixed. It is often useful to keep this function representation in the back of our minds, but we will prefer the graphical interpretation where a neuron is represented by a node, connected to inputs and outputs.&lt;/p&gt;
&lt;h1 id="howdoneuronslearn"&gt;How do neurons learn?&lt;/h1&gt;
&lt;br&gt;
&lt;p&gt;Now that you know how our one-parameter, single input neuron acts on inputs, it's time to see how we can train our neuron to make meaningful predictions. I will demonstrate this with the simplest example I can think of.&lt;/p&gt;
&lt;p&gt;Let's say we're given the following data, collected from three people at the grocery store, where $x$ represents the number of items they purchased and $y$ represents how much they paid, in dollars:&lt;/p&gt;
&lt;p&gt;$$\begin{array}{|c|c|c|}&lt;br&gt;
\hline&lt;br&gt;
\text{Person} &amp;amp; x = \text{Items} &amp;amp; y = \text{Price} \\&lt;br&gt;
\hline&lt;br&gt;
\text{Sally}  &amp;amp; 1                &amp;amp; 2                \\&lt;br&gt;
\hline&lt;br&gt;
\text{Adam}   &amp;amp; 2                &amp;amp; 4                \\&lt;br&gt;
\hline&lt;br&gt;
\text{Fred}   &amp;amp; 3                &amp;amp; 6                \\&lt;br&gt;
\hline&lt;br&gt;
\end{array}$$&lt;/p&gt;
&lt;p&gt;Seeing this table, it might be immediately apparent to you that $y=2x$ for each $x$ in the table. In practice, however, we are often faced with much larger amounts of data that do not follow such a clear trend. We would thus like our neuron to learn for itself how best to make predictions, based on the data. So in this case, we would like the neuron to figure out that it should set $w=2$.&lt;/p&gt;
&lt;p&gt;As simple as the problem is, this is easier said than done. But let's walk through training the neuron on our data set, step by step. To start off, we need to pick some value for $w$, so the neuron can actually do anything at all. Let's choose $w=0$, and see what predictions our neuron makes:&lt;/p&gt;
&lt;p&gt;$$\begin{array}{|c|c|c|}&lt;br&gt;
\hline&lt;br&gt;
x &amp;amp; \hat{y} = wx &amp;amp; y \\&lt;br&gt;
\hline&lt;br&gt;
1 &amp;amp; 0            &amp;amp; 2 \\&lt;br&gt;
\hline&lt;br&gt;
2 &amp;amp; 0            &amp;amp; 4 \\&lt;br&gt;
\hline&lt;br&gt;
3 &amp;amp; 0            &amp;amp; 6 \\&lt;br&gt;
\hline&lt;br&gt;
\end{array}$$&lt;/p&gt;
&lt;p&gt;Here, $\hat{y}$ represents the prediction made given the input value $x$, and $y$ represents the true value from our data set. It's safe to say that choosing $w=0$ is not giving us very good predictions. We would like to adjust $w$ so that the neuron does a better job. In order to do this, we need some way to measure just how badly the neuron is currently performing.&lt;/p&gt;
&lt;p&gt;We define the &lt;strong&gt;loss&lt;/strong&gt; of the neuron for a single input value $x_i$ as follows:&lt;/p&gt;
&lt;p&gt;$$L(x_i) = (y_i - \hat{y_i})^2.$$&lt;/p&gt;
&lt;p&gt;This loss function $L$ basically tells us how badly the neuron is doing at predicting a single value $x_i$. Notice that if the prediction $\hat{y_i}$ is close to the actual value $y_i$, the loss will be small (positive, but close to zero). If the neuron is perfectly predicting the output, the loss will be exactly zero. If the neuron is given an input $x_i$ and spits out a terrible answer $\hat{y}_i$ that is very far from the true answer $y$, then the loss for that input will be huge.&lt;/p&gt;
&lt;p&gt;In the case of our example,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
L(x_1) &amp;amp;= (y_1 - \hat{y}_1)^2 = (2 - 0)^2 = 4, \\&lt;br&gt;
L(x_2) &amp;amp;= (y_2 - \hat{y}_2)^2 = (4 - 0)^2 = 16, \\&lt;br&gt;
L(x_3) &amp;amp;= (y_3 - \hat{y}_3)^2 = (6 - 0)^2 = 36.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Notice that the loss for $x_1$ is small because the prediction is not too far from the actual result. As the predictions get further off, the losses grow exponentially.&lt;/p&gt;
&lt;p&gt;The loss function we've just defined is called the &lt;strong&gt;squared error&lt;/strong&gt;, for obvious reasons. We could have defined a different loss function, if we'd wanted. For instance, we could have taken $L(x_i)=\abs{y_i - \hat{y}_i}$. This is called &lt;strong&gt;absolute error&lt;/strong&gt;, but it is not used very often for reasons we will see shortly. There are plenty of other choices as well, but squared error will do just fine for now.&lt;/p&gt;
&lt;p&gt;Now that we have a measure for how poorly the neuron is performing for a single input, how can we measure how poorly the neuron is doing overall? The answer is simple — we can just average all the losses.&lt;/p&gt;
&lt;p&gt;We define the &lt;strong&gt;cost&lt;/strong&gt; of the neuron to be&lt;/p&gt;
&lt;p&gt;$$C = \frac{1}{m}\sum_{i=1}^m L(x_i),$$&lt;/p&gt;
&lt;p&gt;where $m$ is the total number of data points (so in our case, $m=3$). This is literally just the average loss, computed over all the data. In our case,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
C &amp;amp;= \tfrac{1}{3}\big(L(x_1)+L(x_2)+L(x_2)\big) \\&lt;br&gt;
&amp;amp;= \tfrac{1}{3}(4 + 16 + 36) \\&lt;br&gt;
&amp;amp;= \tfrac{56}{3} \\&lt;br&gt;
&amp;amp;\approx 18.6666666667.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;So the goal now becomes &lt;em&gt;minimizing the cost&lt;/em&gt; of our neuron! Once we have settled on a weight which makes the cost sufficiently low, we say our neuron is &lt;strong&gt;trained&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Okay, so our neuron currently has a cost of $18.6666666667$. This doesn't really tell us too much by itself. We want the network to choose a new weight which will result in a lower cost. How can we accomplish this?&lt;/p&gt;
&lt;p&gt;One idea would be to keep randomly selecting weights and keeping track of which results in the lowest cost, i.e., is giving the best predictions according to our metric.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 1. Random Guessing&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Decide on some reasonable interval $[a, b]$ to search.&lt;/li&gt;
&lt;li&gt;Initialize &lt;code&gt;best_w = 0&lt;/code&gt; and &lt;code&gt;best_cost = infinity&lt;/code&gt; (or some very large number).&lt;/li&gt;
&lt;li&gt;Pick &lt;code&gt;w&lt;/code&gt; randomly in the interval $[a, b]$.&lt;/li&gt;
&lt;li&gt;Compute the cost &lt;code&gt;C&lt;/code&gt; of the neuron with the weight &lt;code&gt;w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;C&lt;/code&gt; is smaller than &lt;code&gt;best_cost&lt;/code&gt;, set &lt;code&gt;best_cost = C&lt;/code&gt; and &lt;code&gt;best_w = w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go back to step 3 and repeat for as long as you like.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;But this is not really a good solution, since there are infinite numbers to choose from and the neuron has no idea where to look. (And in fact, in the general case of a network with many neurons it will probably never find decent weights.)&lt;/p&gt;
&lt;p&gt;What the neuron really needs is some context. Maybe it could try out two new weights, one slightly less than $0$ and one slightly greater than $0$, and see which weight results in a lower cost. So for instance, maybe we could try $-0.1$ and $0.1$. I won't bore you with the details of the computation, but what we end up with is:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
C_{-0.1} &amp;amp;= 20.58, \\&lt;br&gt;
C_{0.1}  &amp;amp;= 16.8466666667.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;What this tells us is that we can get better performance out of our neuron if we increase the weight $w$ from $0$ to $0.1$, whereas if we had decreased the weight then the neuron would have given us worse predictions. This seems correct, since we know in the back of our minds that the value of $w$ that would give perfect predictions is actually $2$, so we certainly want it to increase from $0$. We could keep repeating this process until shifting the weight in either direction would give a worse (higher) cost, and then we would be done.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 2. Weight Sliding&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialize &lt;code&gt;w = 0&lt;/code&gt; and pick a small increment &lt;code&gt;increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compute the costs &lt;code&gt;C_minus&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;C_plus&lt;/code&gt; for the weights &lt;code&gt;w&lt;/code&gt;, &lt;code&gt;w - increment&lt;/code&gt; and &lt;code&gt;w + increment&lt;/code&gt;, respectively.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;C_minus&lt;/code&gt; is less than &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;C_plus&lt;/code&gt;, update &lt;code&gt;C = C_minus&lt;/code&gt; and &lt;code&gt;w = w - increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If instead &lt;code&gt;C_plus&lt;/code&gt; is less than &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;C_minus&lt;/code&gt;, update &lt;code&gt;C = C_plus&lt;/code&gt; and &lt;code&gt;w = w + increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Otherwise, &lt;code&gt;C&lt;/code&gt; is less than &lt;code&gt;C_minus&lt;/code&gt; and &lt;code&gt;C_plus&lt;/code&gt;, so we are done.&lt;/li&gt;
&lt;li&gt;Go back to step 2, but don't bother recomputing &lt;code&gt;C&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;This isn't such a bad method. It will usually tell us which direction we should nudge the weight to improve the neuron's predictions. However, it always takes fixed-size steps, it is not foolproof and it does poorly from a computational standpoint — it requires us to compute the cost three times for each choice of weight, and compare them. It turns out there's a much better way!&lt;/p&gt;
&lt;h1 id="gradientdescent"&gt;Gradient descent&lt;/h1&gt;
&lt;br&gt;
&lt;p&gt;It turns out that we can figure out which direction to shift the weight, and by how far, with a single computation. The actual method requires some knowledge of calculus, but the basic ideas should make sense to anyone following along. Just don't get scared off by the derivatives if you don't know what they are.&lt;/p&gt;
&lt;p&gt;Here is a plot of the cost for our neuron for a whole interval of possible weights. I computed this by calculating the cost associated with a bunch of weights in the interval $[-1, 5]$.&lt;/p&gt;
&lt;iframe width="500" height="400" frameborder="0" scrolling="no" src="//plot.ly/~eshapiro/18.embed"&gt;&lt;/iframe&gt;
&lt;p&gt;Computing this whole graph is similar to Algorithm 2 above. That is, it's very inefficient and computationally intensive. The graph is solely for the sake of our visualizing the problem. Our neuron does not know the shape of the cost function, so it needs some other way update its weight for a better prediction.&lt;/p&gt;
&lt;p&gt;The inspiration behind the gradient descent algorithm comes from the idea of a ball rolling down a hill. The idea is that gravity will always pull the ball in the direction of &lt;em&gt;steepest descent&lt;/em&gt;. For a visualization, press &amp;quot;Play&amp;quot; on the animation below.&lt;/p&gt;
&lt;iframe width="500" height="400" frameborder="0" scrolling="no" src="//plot.ly/~eshapiro/82.embed"&gt;&lt;/iframe&gt;
&lt;p&gt;Of course, in real life the momentum of the ball would keep it moving to the right for a little while after it reached the bottom, then it would change directions and oscillate for a short time before finally settling at the bottom. But we don't care too much about the details, only the general idea.&lt;/p&gt;
&lt;p&gt;It just so happens that we have a way to compute, at any given point, the direction of steepest descent. Recall that the derivative of a function at a point (if it exists) tells us geometrically the slope of the tangent line to the function's curve at that point. Here's what the tangent line to the cost curve looks like when $w=0$:&lt;/p&gt;
&lt;iframe width="500" height="400" frameborder="0" scrolling="no" src="//plot.ly/~eshapiro/83.embed"&gt;&lt;/iframe&gt;
&lt;p&gt;The slope of this tangent line is negative, implying that the cost is decreasing as we move to the right. This means that if the derivative is negative, we want to shift our weight to the right. And if the derivative is positive, we want the weight to shift to the left.&lt;/p&gt;
&lt;p&gt;Since the derivative at $w=0$ is negative, we shift $w$ to the right a bit, then reevaluate:&lt;/p&gt;
&lt;iframe width="500" height="400" frameborder="0" scrolling="no" src="//plot.ly/~eshapiro/85.embed"&gt;&lt;/iframe&gt;
&lt;p&gt;The derivative is still negative, but it's &lt;em&gt;less&lt;/em&gt; negative. So we should continue to shift $w$ to the right, but maybe not as much this time.&lt;/p&gt;
&lt;p&gt;If we continue this process, we should eventually shift $w$ to $2$, where the derivative is $0$. That is, the cost has a horizontal tangent line at this point. This is what tells us we have found a weight that minimzes the cost!&lt;/p&gt;
&lt;p&gt;The amount that we shift $w$ by in each iteration should be &lt;em&gt;proportional&lt;/em&gt; to the magnitude of the derivative. That way it will move by a lot more when the cost is very high and a lot less when the cost is very low, so we don't overshoot our target by too much. Said another way, this will guarantee that if our weight is close to optimal, we shift it by a smaller amount than if it is far from optimal. We call this proportionality constant the learning rate, and I will talk more about learning rates in another post.&lt;/p&gt;
&lt;p&gt;So here's the algorithm:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 3. Gradient Descent&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pick an initial weight &lt;code&gt;w&lt;/code&gt; using some predetermined method, and a small learning rate &lt;code&gt;learning_rate&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compute the derivative of the cost with respect to &lt;code&gt;w&lt;/code&gt;, call it &lt;code&gt;D_w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Update &lt;code&gt;w = w - learning_rate * D_w&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go back to step 2 and repeat for as long as you like, or until &lt;code&gt;D_w&lt;/code&gt; is zero.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h1 id="computingthegradient"&gt;Computing the gradient&lt;/h1&gt;
&lt;br&gt;
&lt;p&gt;Since our neuron only has one weight to optimize, in this case 'gradient' just means derivative. We will shortly see an example where this is no longer the case. But for now, we need to figure out a way of calculating the derivative of our cost function for a specific value of $w$. That is, we need to find $\d{C}{w}$.&lt;/p&gt;
&lt;p&gt;Recall that $C$ is a function of the losses $L_i$, which are in turn functions of the outputs $\hat{y_i}$, which are in turn functions of the inputs $x_i$. Here are the equations governing these relationships:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
C &amp;amp;= \frac{1}{m}\sum_{i=1}^m L_i, \\&lt;br&gt;
L_i &amp;amp;= (y - \hat{y})^2, \\[1em]&lt;br&gt;
\hat{y}_i &amp;amp;= wx_i.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;The chain rule tells us precisely how to calculate $\d{C}{w}$ from these equations! Through repeated use of the chain rule, we see that:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\d{C}{w} &amp;amp;= \sum_{i=1}^m\p{C}{L_i}\d{L_i}{w} \\&lt;br&gt;
&amp;amp;= \sum_{i=1}^m\p{C}{L_i}\d{L_i}{\hat{y_i}}\d{\hat{y_i}}{w}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;These three quantities are easy to calculate from the equations above:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\p{C}{L_i} &amp;amp;= \tfrac{1}{m}, \\&lt;br&gt;
\d{L_i}{\hat{y_i}} &amp;amp;= -2(y_i-\hat{y_i}), \\&lt;br&gt;
\d{\hat{y_i}}{w} &amp;amp;= x_i.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Combining these using the chain rule, we see that&lt;/p&gt;
&lt;p&gt;$$\d{C}{w} = -\frac{2}{m} \sum_{i=1}^m (y_i-\hat{y_i})x_i.$$&lt;/p&gt;
&lt;p&gt;This means we can use the following algorithm to compute the gradient of our cost function for a particular value of $w$:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Algorithm 4. Gradient Computation&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialize &lt;code&gt;D_w=0&lt;/code&gt;, set &lt;code&gt;x&lt;/code&gt; to the first input and &lt;code&gt;y&lt;/code&gt; to its corresponding output in our data set, and set &lt;code&gt;m&lt;/code&gt; to the number of data points.&lt;/li&gt;
&lt;li&gt;Compute the neuron's output &lt;code&gt;y_hat = w * x&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compute the contribution to &lt;code&gt;D_w&lt;/code&gt; from this data point, &lt;code&gt;D_w = D_w - 2 * (y - y_hat) * x&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;x&lt;/code&gt; to the next input and &lt;code&gt;y&lt;/code&gt; to its corresponding output, go back to step 2 and repeat until we have exhausted all our data.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;D_w = D_w / m&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h1 id="puttingittogether"&gt;Putting it together&lt;/h1&gt;
&lt;br&gt;
&lt;p&gt;We have now completely described our one-parameter neuron and how it learns! Below is some Python code which encapsulates our model and allows us to train a neuron given input and output data. The first class, &lt;code&gt;Neuron&lt;/code&gt;, is a base class which we will continue to use as we implement more complex neurons. The second, &lt;code&gt;OneParameterNeuron&lt;/code&gt;, inherits from Neuron and is a complete model of our on-parameter neuron.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import time
from abc import abstractmethod

class Neuron:
    def __init__(self):
        self.total_epochs = 0
        self.parameters = {}
        
    @abstractmethod
    def predict(self, input):
        pass
    
    @abstractmethod
    def compute_gradient(self, inputs, true_outputs):
        pass
            
    @abstractmethod
    def gradient_descent(self, inputs, true_outputs, learning_rate):
        pass
    
    def loss(self, actual, prediction):
        return (actual - prediction)**2
        
    def cost(self, inputs, true_outputs):
        sum_of_losses = 0
        for idx, input in enumerate(inputs):
            prediction = self.predict(input)
            actual = true_outputs[idx]
            sum_of_losses += self.loss(actual, prediction)
        return sum_of_losses / len(inputs)
    
    def train(self, inputs, true_outputs, epochs=100, learning_rate=0.01):
        start = time.time()
        for epoch in range(epochs):
            self.gradient_descent(inputs, true_outputs, learning_rate)
            if epoch == 0 or (epoch + 1) % 10 == 0 or epoch == epochs - 1:
                end = time.time()
                cost = self.cost(inputs, true_outputs)
                print(f'Epoch: {self.total_epochs + 1:&amp;lt;10} '
                      f'Cost = {cost:&amp;lt;20.9E} '
                      f'Time = {1000 * (end - start):.9f}ms')
                start = time.time()
            self.total_epochs += 1
            
class OneParameterNeuron(Neuron):
    def __init__(self):
        super().__init__()
        self.parameters = {'w': 0}
        
    def predict(self, input):
        return self.parameters['w'] * input
    
    def compute_gradient(self, inputs, true_outputs):
        D_w = 0
        for idx, input in enumerate(inputs):
            actual = true_outputs[idx]
            prediction = self.predict(input)
            D_w += -2 * (actual - prediction) * input
        D_w /= len(inputs)
        return D_w
            
    def gradient_descent(self, inputs, true_outputs, learning_rate):
        gradient = self.compute_gradient(inputs, true_outputs)
        self.parameters['w'] -= learning_rate * gradient
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Calling the &lt;code&gt;train&lt;/code&gt; method for a neuron launches 100 iterations, or &lt;strong&gt;epochs&lt;/strong&gt;, of gradient descent. It defaults to zero as an initial choice of weight, and uses a learning rate of $0.01$.&lt;/p&gt;
&lt;p&gt;Let's see it in action!&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-1?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;It actually works! Look how small our model got the cost after just 100 epochs of gradient descent! And look how close it got to the optimal value of $w=2$.&lt;/p&gt;
&lt;p&gt;There are some huge improvements that could be made to this code, in particular the &lt;code&gt;cost&lt;/code&gt; and &lt;code&gt;compute_gradient&lt;/code&gt; methods could be drastically sped up. However, this accurately reflects the algorithms we've discussed so far.&lt;/p&gt;
&lt;p&gt;It could be interesting to try training our neuron on a larger, not-so-perfect data set. We'll use this data, which consists of 1000 points which follow the same general trend as our previous data, but no longer sit perfectly on the line $y=2x$. This is more like data we might encounter in the real world!&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="//plot.ly/~eshapiro/89.embed"&gt;&lt;/iframe&gt;
&lt;p&gt;Watch what happens when we train our neuron with this new data:&lt;/p&gt;
&lt;iframe height="600px" width="100%" src="https://repl.it/@EricShapiro/Linear-Regression-with-Neurons-2?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;It still did a pretty good job! Of course, it can't get the cost down as low anymore, but that's because the data is no longer perfectly linear and so there is some unavoidable error in any linear model of the data. Here is the trendline that our model predicted, superimposed on the data:&lt;/p&gt;
&lt;iframe width="100%" height="400" frameborder="0" scrolling="no" src="//plot.ly/~eshapiro/93.embed"&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;p&gt;I'd say that looks pretty good! As a comparison, least-squares linear regression predicts a slope of $1.95148117$ for this same data.&lt;/p&gt;
&lt;p&gt;This post is getting pretty long, so I'll leave it at that for now. In my next post, we'll improve our neuron by adding a second parameter, and we'll see how this makes everything a bit more complicated.&lt;/p&gt;
&lt;!--kg-card-end: markdown--&gt;</content:encoded></item></channel></rss>